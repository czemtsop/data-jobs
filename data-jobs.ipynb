{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation and creating DataFrames\n",
    "import requests  # For making HTTP requests to the API\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "def fetch_remoteok_jobs_from_api():\n",
    "    \"\"\"\n",
    "    Fetches job listings from the RemoteOK API.\n",
    "\n",
    "    The RemoteOK API returns a list. The first element is often a legal notice or API information,\n",
    "    so we skip it to get to the actual job listings.\n",
    "\n",
    "    Returns:\n",
    "        data: A list of job dictionaries if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    api_url = \"https://remoteok.com/api\"\n",
    "    print(f\"Attempting to fetch data from: {api_url}\")\n",
    "    try:\n",
    "        response = requests.get(api_url, timeout=10)  # Added timeout for robustness\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses (4XX or 5XX)\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # The RemoteOK API returns a list. The first item is a \"legal notice\" or API info.\n",
    "        # Actual job listings start from the second item.\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            if data[0].get(\"legal\") is not None:\n",
    "                print(f\"Skipping the first element (meta-data/legal): {data[0].get('legal')}\")\n",
    "                return data[1:]  # Return the rest of the list\n",
    "            else:\n",
    "                # If the first element doesn't look like metadata, perhaps the API structure changed.\n",
    "                # For now, we'll assume it's all job data.\n",
    "                print(\"First element does not appear to be metadata. Processing all elements as data-jobs.\")\n",
    "                return data\n",
    "        elif isinstance(data, list) and len(data) == 0:\n",
    "            print(\"API returned an empty list of data-jobs.\")\n",
    "            return []\n",
    "        else:\n",
    "            print(f\"Unexpected API response format. Expected a list, got {type(data)}.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error: Request to {api_url} timed out.\")\n",
    "        return None\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"Error: HTTP error occurred: {http_err} - Status Code: {response.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"Error: An error occurred while fetching data from API: {req_err}\")\n",
    "        return None\n",
    "    except ValueError as json_err:  # Includes json.JSONDecodeError\n",
    "        print(f\"Error: Could not decode JSON response: {json_err}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_jobicy_jobs_from_api():\n",
    "    \"\"\"\n",
    "    Fetches job listings from the Jobicy API.\n",
    "\n",
    "    The Jobicy API returns a list where the first element contains API information,\n",
    "    so we skip it to get to the actual job listings.\n",
    "\n",
    "    Returns:\n",
    "        data: A list of job dictionaries if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    api_url = \"https://jobicy.com/api/v2/remote-jobs\"\n",
    "    print(f\"Attempting to fetch data from: {api_url}\")\n",
    "    try:\n",
    "        response = requests.get(api_url, timeout=10)  # Added timeout for robustness\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses (4XX or 5XX)\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # The RemoteOK API returns a list. The first item is contains API info.\n",
    "        # Actual job listings are in the second item.\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            if data[0].get(\"friendlyNotice\") is not None:\n",
    "                print(f\"Skipping the first element (meta-data/legal): {data[0].get('friendlyNotice')}\")\n",
    "                return data[1].get('data-jobs')  # Return the job list\n",
    "            else:\n",
    "                # If the first element doesn't look like metadata, perhaps the API structure changed.\n",
    "                # For now, we'll assume it's all job data.\n",
    "                print(\"First element does not appear to be metadata. Processing all elements as data-jobs.\")\n",
    "                return data\n",
    "        elif isinstance(data, list) and len(data) == 0:\n",
    "            print(\"API returned an empty list of data-jobs.\")\n",
    "            return []\n",
    "        else:\n",
    "            print(f\"Unexpected API response format. Expected a list, got {type(data)}.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error: Request to {api_url} timed out.\")\n",
    "        return None\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"Error: HTTP error occurred: {http_err} - Status Code: {response.status_code}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"Error: An error occurred while fetching data from API: {req_err}\")\n",
    "        return None\n",
    "    except ValueError as json_err:  # Includes json.JSONDecodeError\n",
    "        print(f\"Error: Could not decode JSON response: {json_err}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_jobs_to_structured_dataframe(job_list):\n",
    "    \"\"\"\n",
    "    Parses a list of job dictionaries (from API) into a pandas DataFrame.\n",
    "    Selects relevant columns and performs basic data cleaning/transformation.\n",
    "\n",
    "    Args:\n",
    "        job_list (list): A list of dictionaries, where each dictionary represents a job.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing structured job data, or an empty DataFrame if input is invalid.\n",
    "    \"\"\"\n",
    "    if not job_list or not isinstance(job_list, list):\n",
    "        print(\"No job data provided or data is not in list format. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Normalizing {len(job_list)} job entries into a DataFrame...\")\n",
    "    # Use pandas.json_normalize to flatten the JSON structures.\n",
    "    df = pd.json_normalize(job_list)\n",
    "\n",
    "    # --- Data Cleaning and Transformation ---\n",
    "\n",
    "    # Define the columns we are interested in.\n",
    "    desired_columns = [\n",
    "        'id', 'company', 'position', 'tags', 'location', 'salary_min', 'salary_max'\n",
    "    ]\n",
    "    # Define the keywords to look for in job titles\n",
    "    keywords = 'analy|data|machine learning|intelligence'\n",
    "\n",
    "    # Select only the desired columns that are actually present in the DataFrame\n",
    "    # This makes the script more robust to changes in the API response\n",
    "    columns_to_select = [col for col in desired_columns if col in df.columns]\n",
    "\n",
    "    if not columns_to_select:\n",
    "        print(\"None of the desired columns were found in the API response. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_selected = df[columns_to_select][df['position'].str.contains(keywords, case=False) |\n",
    "                                        df['tags'].str.contains(keywords,\n",
    "                                                                case=False)].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Convert 'epoch' to datetime objects\n",
    "    if 'epoch' in df.columns:\n",
    "        # Ensure 'epoch' is numeric, coercing errors to NaT (Not a Time)\n",
    "        df_selected['epoch'] = pd.to_datetime(df['epoch'], unit='s', errors='coerce')\n",
    "\n",
    "    # Convert 'tags' list into a comma-separated string for easier use in SQL/CSV.\n",
    "    if 'tags' in df_selected.columns:\n",
    "        df_selected['tags_string'] = df_selected['tags'].apply(\n",
    "            lambda tags_list: ', '.join(tags_list) if isinstance(tags_list, list) and tags_list else None\n",
    "        )\n",
    "\n",
    "    # Clean up HTML and robot message from description\n",
    "    if 'description' in df.columns:\n",
    "        df_selected['description'] = df['description'].apply(\n",
    "            lambda html: bs(html, 'html.parser').get_text()\n",
    "        )\n",
    "        df_selected['description'] = df_selected['description'].str.replace(r'Please mention the word(.)*', \"\",\n",
    "                                                                            regex=True)\n",
    "\n",
    "    return df_selected\n",
    "\n",
    "\n",
    "def analyze_job_data(job_postings):\n",
    "    \"\"\"Performs basic analysis on the fetched job listings.\"\"\"\n",
    "\n",
    "    all_descriptions = \", \".join(job_postings.description).lower()\n",
    "    keywords = all_descriptions.split()\n",
    "    common_keywords = Counter(keywords).most_common(20) # Get the top 20 most frequent words\n",
    "\n",
    "    print(\"\\nTop 20 most common keywords in job descriptions:\")\n",
    "    for keyword, count in common_keywords:\n",
    "        if keyword not in STOPWORDS: # Basic stop word removal\n",
    "            print(f\"- {keyword}: {count}\")\n",
    "\n",
    "    # Generate word cloud using tags on job postings\n",
    "    tags = \", \".join(job_postings.tags_string).lower()\n",
    "\n",
    "    wordcloud = WordCloud().generate(tags)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"--- Starting RemoteOK Job Data Pipeline ---\")\n",
    "\n",
    "# Step 1: Fetch job data from the API\n",
    "raw_job_data = fetch_remoteok_jobs_from_api()\n",
    "raw_job_data2 = fetch_jobicy_jobs_from_api()\n",
    "\n",
    "if raw_job_data is None:\n",
    "    print(\"Failed to fetch job data from remoteok. Exiting pipeline.\")\n",
    "\n",
    "if not raw_job_data:\n",
    "    print(\"No job listings fetched from the API. Exiting pipeline.\")\n",
    "\n",
    "print(f\"Successfully fetched {len(raw_job_data)} raw job entries.\")\n",
    "\n",
    "# Step 2: Parse and transform data into a pandas DataFrame\n",
    "jobs_dataframe = parse_jobs_to_structured_dataframe(raw_job_data)\n",
    "\n",
    "if jobs_dataframe.empty:\n",
    "    print(\"DataFrame creation failed or resulted in an empty DataFrame. Exiting pipeline.\")\n",
    "\n",
    "print(\"\\n--- DataFrame Information ---\")\n",
    "jobs_dataframe.info()\n",
    "\n",
    "analyze_job_data(jobs_dataframe)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
